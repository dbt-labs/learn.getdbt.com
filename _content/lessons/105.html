---
layout: presentation
title: Data Warehouse Design
lesson: 105
estimated_teaching_time: 60
teaching_method: slides
working_session: false
---

# Data Warehouse Design

---

layout: false

# Talk of the town

- Dimensional modeling _(Kimball 1996)_
- Data normalization
- Snowflake / star schema
- Data “marts”
- Agile / BEAM (Business Event Analysis & Modelling) _(Corr 2011)_

---

# Back in the nineties

Data is data is data is data. There isn't a well understood distinction between
"source" data and "transformed" data. (Secretly, teams of data
engineers are transforming data all the time, but you wouldn't know it.)

<img src="/lessons/img/105_1.png" class="img-center">

---

<img src="/lessons/img/105_2.png" class="img-center">

---

# I'm thinking of a model...

Kimball says:
1. What is the business process?
2. What is the grain (primary key)?
3. What are the "nouns" (dimensions)?
4. What are the "verbs" (facts)?

Corr says: 7Ws
- **w**ho
- **w**hat
- **w**hen
- **w**here
- ho**w** many
- **w**hy
- ho**w**

---

# Balancing act

Any set of best practices in model design have always needed to balance between
two competing interests:

- **Intuition:** speed of comprehension for human analysts

- **Performance:** speed of operation for (non-human) database

_As modern data practitioners, we are inheritors of a decades-long history. It
is our task to determine for the present day which concepts are still necessary, and which
implementation strategies are still applicable._

---

# What's changed?

.left-column[
## Then
- Data Engineers own ETL (“Extract-Transform-Load”)
- Storage and aggregations are expensive
- Joins are cheap
- Data is federated between dozens/hundreds of objects
]

.right-column[
## Now
- Off-the-shelf tools (e.g. Stitch, Fivetran) can manage >90% of extract + load
- Storage and aggregations are cheap
- Scanning, joining, updating data is expensive
- Datasets are massive and partitioned
]

---

# Before

<img src="/lessons/img/105_3.png" class="img-center">

---

# Before

```sql
SELECT
	B.Brand,
	G.Country,
	SUM(F.Units_Sold)
FROM Fact_Sales F
INNER JOIN Dim_Date D             ON F.Date_Id = D.Id
INNER JOIN Dim_Store S            ON F.Store_Id = S.Id
INNER JOIN Dim_Geography G        ON S.Geography_Id = G.Id
INNER JOIN Dim_Product P          ON F.Product_Id = P.Id
INNER JOIN Dim_Brand B            ON P.Brand_Id = B.Id
INNER JOIN Dim_Product_Category C ON P.Product_Category_Id = C.Id
WHERE
	D.Year = 1997 AND
	C.Product_Category = 'tv'
GROUP BY
	B.Brand,
	G.Country
```

---

# After

<img src="/lessons/img/105_4.png" class="img-center">

---

# After

```sql
select

	brand,
	country,
	sum(units_sold) as total

from analytics.fact_sales
where date_trunc('year', sale_date) = '1997-01-01'
  and product_category = 'tv'

group by 1,2
```

---

template: title

# Interfaces

---

# Interface #1: The Graph

"Where are those sales numbers coming from?"

_Which data sources, processes, and assumptions do our sales calculations depend on?_

The graph tells a story:

<h3 style="text-align: center;"><span style="color: green;">Source</span>
&rarr;
<span style="color: blue;">Staging</span>
&rarr;
<span style="color: purple;">Dimensions + Facts</span></h3>

---

# Interface #2: The Code

Within files: adhere to a style guide

Between files: better file organization = easier onboarding + better collaboration

```
├── README.md
├── dbt_project.yml
└── models
    ├── marts
        └── core
            ├── core.yml
            └── dim_product.sql
            ├── dim_store.sql
            └── fact_sales.sql
    └── staging
        └── postgres
        └── shopify
            ├── shopify.yml
            ├── stg_shopify_customers.sql
            ├── stg_shopify_order_items.sql
            ├── stg_shopify_orders.sql
            └── stg_shopify_products.sql
```

---

# Interface #3: The Warehouse

.left-column-66[
- **Nomenclature.** How do we name our views + tables so they are consistent, easy to
find, and easy to infer contents?
- How do we organize our output objects? Same schema or different?
- What about the intermediate stuff we _don’t_ want to show?
- Who is your end user? Is it a person writing SQL, or a BI tool pointed to a production schema?
]

<img src="/lessons/img/105_6.png" style="width: 30%; float: right;">

---

template: title
# The way we roll

---

# [How we structure our dbt projects](https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355)

<img src="/lessons/img/105_7.png" class="img-center">
&nbsp;
<img src="/lessons/img/105_8.png" class="img-center">

---

# Model prefixes: must-haves

.dense-text[
.left-column-33[
### stg_
- 1:1 with raw data tables
- Renaming, type casting, coalescing + nullif’ing
- Views!
]

.right-column-66[
.left-column[
### dim_
- “Nouns”
- Customers, products, apartments, providers, employees
- Some "slowly-changing" attributes (e.g. address, email)
- Tables!
]

.right-column[
### fct_
- “Verbs”
- Core business process
- Often built on top of an immutable event stream
- Orders, cases, plays, listings, comments
- Tables (maybe incremental)
]]]

---

# Also seen in the wild

.dense-text[
.left-column-33[
### __[transformed]
- Intermediate models accomplishing a transformation step
- Not meant for public consumption
- orders__amortized
- Views (can be tables if more performant)
- Different schema?
]

.right-column-66[
.left-column[
### utils, lookups, seeds
- Handy-dandy tables to make your life easier
- Calendars: days/months, retail, biz hours
- Mapping tables (country codes --> region, products --> plans)
]

.right-column[
### metric_
- Version-controlled definitions of biz KPIs
- Can be fed into a union/spine/window process to generate a single-source-of-truth metrics table
- Next-level stuff! Assumes you already have full assortment of facts + dims at the ready
]]]

---

<h3 style="text-align: center;"><span style="color: green;">source</span>
&rarr;
<span style="color: lightblue; font-size: 60%;">[base]</span>
&rarr;
<span style="color: blue;">stg</span>
&rarr;
<span style="color: grey; font-size: 60%;">[intermediate, lookup, utils]</span>
&rarr;
<span style="color: purple;">fct</span>
&harr;
<span style="color: navy;">dim</span></h3>

<img src="/lessons/img/105_9.png" style="width: 100%;">

???
Instructor: draw circles/boxes around the different "model groups" (sources,
staging, intermediate, lookups, final fact/dim). Comment on how they can
be grouped together in all three interfaces.

---

# Unofficial rules of thumb

1. Nomenclature is _hard_, and it's worth your time to be consistent. It doesn't
matter if you prefer `fct_` or `fact_`, it's important that you choose one. (What's not hard? 
Every model/object name is snake case + case insensitive.)
2. Prefixed models represent usable assets. Double underscores represent private/internal methods.
3. Individual models should max out at a half-dozen CTEs / few hundred lines of SQL.
4. Model code should seek to be DRY (Don't Repeat Yourself) and easily readable. Use
Jinja + macros strongly and sparingly.
5. Final models (facts + dimensions) are multipotent, and each can power several
queries. Your end user (or BI tool) should be able to answer 80% of its most common
questions by querying 1 table. Of the reamining 20%, no query (outside of _truly_ ad hoc
analysis) should need more than two join "steps."
6. Dimensional modeling _is_ feature engineering. Analysts, BI users, and
data scientists all can and should be beneficiaries of the same foundational work.

???
In other people's naming, the "semantic" layer ~ our staging layer
I think about join "steps" as degrees of Kevin Bacon

---

template: title
# So what are BI tools for, anyway?

???
It's not uncommon that we deliver this presentation and students walk away
with the unfounded assertion that dbt can do _everything_. Why are they paying
so much for their BI tool??

---

## The same things they’ve always been good at!

- User Interface
    - Point-and-click
    - Self-service
    - Accessible to less technical users
- Viz!
    - Out-of-the-box
    - Frameworks/libraries
- Reporting nice-to-haves
    - Dynamic parameters
    - Scheduling, alerting, PDF’ing and CSV’ing
    
---

## Not the things they're bad at... :)

- Multilayered data transformation with complex ordered dependencies
- Enforcing a single sources of truth
    - Defining, documenting, centralizing business logic
- Maintaining separate data environments
    - Testing
    - Version control
- Running a lot non-performant SQL concurrently
- Managing user access to sensitive data

---

# What goes where?

.left-column[
## dbt layer
- Critical business logic
- Best agreed-on version of a model
- Complex SQL
- No wasted code! Everything is multipurpose*
]

.right-column[
## BI layer
- Aggregations (esp. `distinct`)
- Joins qualified by a parameter (user input)
- Specific, one-off "models"
- Select-star SQL + R, Python, JS (custom viz)
]

???
dbt models are like kitchen tools. The only single-purpose kitchen applicance
you should ever have is a rice cooker.

BI assets are like recipies. It doesn't hurt as much to have similar ones, but 
when it comes time to make dinner, your guests might become confused :)

---

# Example, revisited

{% raw %}
```sql
select

	brand,                         -- stacked bar position (x-axis)
	country,                       -- stacked bar color
	sum(units_sold) as total       -- stacked bar height (y-axis)

from {{environment}}.fact_sales    -- switch between dev / prod

-- dynamic reporting parameters / dimension groups
where year = {{param_year}}        
  and product_category = '{{param_product_category}}'

group by 1,2
```
{% endraw %}

---

# Who can write that SQL?

<img src="/lessons/img/105_10.png" class="img-center">
---

# Working session

Refactor your project to be consistent with how we (Fishtown) structure our dbt project. Consider
- model naming
- organization within directories
