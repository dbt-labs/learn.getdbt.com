---
layout: presentation
title: Big Data Technologies
lesson: 206
---

class: title, center, middle
# "Big Data" Technologies

---



# Apples to oranges...

| tech | stored as | storage/ compute | optimization | semi-structured data | "external" data | intuition |
|----------|-----------|------------------|-------------------------|----------------------|----------------------|-----------------------------------------------------|
| Postgres | rows | same | indexes | some support | via extensions? | everything works the way you expect |
| Redshift | columns | tightly coupled | sort + dist | minimal support | S3 via Spectrum | most things |

???
### Postgres
- Stores rows of structured, tabular data
- High concurrency, decent parallelization
- Compute and storage are tightly locked
- Performance optimization via indexes
- Decent support for semi-structured (JSON) data (as of version 9!)
- Shaky support for querying "foreign" data (via extensions)
- Everything works the way you expect
]

### Redshift
- Stores columns of structured, tabular data in proprietary file format
- Massively parallel query execution across multiple workers
- Compute and storage are interrelated
- Performance optimization via sorting, distribution
- Minimal support for semi- and unstructured data (JSON)
- Decent support for querying "external" data in S3 (via Spectrum)
- Most things work the way you expect

--
| Spark | files | separate | file formats + metadata | first-class support | all data is external | <span style="background-color: yellow;">no guarantees</span> |

# ...to mangosteens

???

### Spark
- "Data Lake": All data is stored externally
- Storage and compute are _completely_ separate. You pay for them independently.
- Performance optimization means storing in a columnar file format (parquet)
with excellent metadata
- Semi- and unstructured data is a first-class citizen, with pretty good SQL
functionality
- There's no guarantee that things will work the way you expect!


---

# Why not?

### Spark, Presto, Hive, Athena

- This a blog post I need to write :)

- They each have their fans, and their appropriate target audience!

- Basically:
    - They are incredibly powerful and cost-effective.
    - They're harder to use, and harder to reason about.

---

# What is a modern data warehouse?

It offers the best of both worlds:
    
- Intuitive **user experience** of a database: users, groups/roles,
authentication, permissions, information schema, everything is SQL

- Flexible and scalable **performance** of a data lake + distributed
processing technology

--

Who are best in class?
- Snowflake + BigQuery. These are data lakes posing as data warehouses.
- Redshift is playing catch-up with Spectrum + RA3 nodes

--

What sets them apart?
- Support for semi-structured data
- Support for external data
- Separation of compute + storage

---

# Semi-structured data

It's common that 90% of your data is tabular/structured, but there's a little
bit that makes more sense as JSON!

| bldg_id | location | occupancy | vacant_units | amenities |
|---------|-------------|-----------|--------------|----------------------------------------------------------------------------|
| 1 | Rittenhouse | 54 | `[1, 3, 9]` | `{“doorman”: true, “Pets_allowed”: true, “Pets_allowed_with_deposit”: 1000}` |
| 2 | Fairmount | 8 | `[]` | `{ “Yard_size_sqft”: 100 }` |
| 3 | Austin, TX | 5 | `[1]` | `{ “Yard_size_sqft”: 1,000 }` |

--

&nbsp;

| JSON support           | Redshift      | Snowflake                           | BigQuery                            |
|------------------------|---------------|-------------------------------------|-------------------------------------|
| Unnesting dictionaries | Kind of       | Yes definitely! `amenities:doorman` | Yes definitely! `amenities.doorman` |
| Flattening arrays      | Not natively  | Yes! `lateral flatten`              | Yes! `cross join unnest`            |
| Loading data           | Flatten first | Load as-is                          | Load as repeated records            |


---

# External data

Can your database query files living in S3, Google Cloud Storage, Azure blob storage...?

| External support           | Redshift      | Snowflake                           | BigQuery                            |
|----------------------------|------------------------------------------------|------------------------------------------|--------------------------------------------|
| COPY from/to               | Yes, for S3                                    | Yes, for S3/GCS/Azure                    | Yes, can query GCS + G Drive               |
| Read from external tables  | Yes! Via Spectrum. Manual partitioning         | Yes! All via DDL, automatic partitioning | Yes! Powerful schema inference, but no DDL |
| External-only transform    | Limited cf. Athena                             | Extensive                                | Limited                                    |

---

# Separation of storage + compute

When data is small and transformation is straightforward, you don't mind
that these are locked in a tight aspect ratio
- "I'd like another node, please!"
- Everyone is sharing the same scarce resources

What if you want more storage, without needing to pay for more compute nodes?
What if you want it _now_?
- How do you know how much storage you need? (easy)
- How do you know how much compute you need? (hard)
- AWS/Azure/GCloud sell you "spot instances" of compute resources
- Data is never stored "on disk" because you spin up + spin down compute only
when you need it

---

# What if you have petabytes of data?

<img src="/lessons/img/{{page.lesson}}/jt-billion-rows.png" class="img-center">

---

# Different modeling paradigms
    
- All models are materialized incrementally, and never fully refreshed
- Testing is relative: `unique` and `not_null` failures < 1%
- Tables are "sharded" by a top-level identifier: region, account, client, etc.
    
--
    
### And what if that data is constantly arriving?

- Real-time directional signals on top of _streaming_ datasets (Kafka, Kinesis, oh my...)
- That data is funneled into external permanent storage
- All-time historical aggregates from batch incremental transformations
- A lot of our friendly abstractions + assumptions are out the window...

---

class: subtitle, middle, center
# Speaking of modeling paradigms...
