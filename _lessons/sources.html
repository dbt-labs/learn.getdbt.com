---
layout: presentation
title: Sources
estimated_teaching_time: 30
teaching_method: live demo + slides. Questions encouraged.
working_session: true
learningObjectives:
  - Configure Sources
  - Build dependencies between sources and models
  - Configure tests for sources
  - Configure freshness snapshots
  - Build intuition for why defining sources can be helpful in the future
---

class: title, center, middle
# Sources


???
**Continue the story:** Make a connection to content that was just covered and how we might build off it.

Example: "Excellent! We just concluded testing with Alexis and I'm excited to roll out sources with you all.  You may have noticed that we have been referencing raw tables in some of our models - we are going to figure out why that might be a problem for the future and what we might do about it!"

---

# If you've ever had this happen...

- I'm switching my email marketing platform. I want to know which final models depend on that source data.

???
**Hook:** Use this an an opportunity to drive engagement and get folks invested in this lesson.

Examples:
- Give me an emoji reaction on zoom for each statement that resonates with you. *narrate how popular/common each responses is.*
- For a line that gets a lot of responses, call on 1-2 students to share their story of that case.

--

- I'm switching from Redshift to Snowflake. All of my source data will be
in a different database and schema.

--

- Someone asked me "where does this data _really_ come from?"

--

- Nothing in this world is perfect. My data loading tools experience occasional
hiccups that result in delayed or duplicated data.

--

- Something that was once true about my source data is no longer true (e.g. a
new payment method was introduced)



---
???

Read aloud the text on the slides: 

# Sources may be right for you!

- Easily declare and update the location of raw tables
    - `database` + `schema` for each source
    - `name`/`identifier` for each table
--
- Test data integrity of raw tables
    - Built-in: `unique`, `not_null`, `accepted_values`, `relationships`
    - Custom: whatever you want!
--
- Test the freshness of loaded data, based on thresholds you define

---

{% include options/focus_slide.html %}

???

**Focus Slide:** This is your opportunity to bring focus to the rest of the session. You can do this by... 
- slowing down just a little bit and reading each line with a little context OR
- asking a learner to read these to the room

---

# Defining sources

???

- Sources are defined in `.yml` files in your `models/` directory, where they have to be nested under a source key. 
You will have to provide a source name, which is usually the name of the schema of your raw table. Snowflake users,
you can also provide a database name and then after that you can list your table names. 
- If one of your source tables is badly named, there is also an opportunity for you to provide an alias using the identifier key.

Sources are defined in `.yml` files in your `models/` directory.

(They can co-exist with `models:` blocks)

```yml
version: 2

sources:
  - name: jaffle_shop
    database: raw
    schema: jaffle_shop
    tables:
      - name: customers
        identifier: customers
      - name: orders
        identifier: orders

```

---

# Selecting from sources

???

  - Once you have defined a source in your .yml file, you can now utilize the source Jinja function to select from that source in a model. 
  - The source function here will compile to the full object name in the database, so select star from source-jaffleshop will compile to raw.jaffleshop.customers, with the database name raw, which is **clicks back** how we defined it in our yml file.

Use the {% raw %}`{{ source() }}`{% endraw %} function to select from a source in a model:

.left-column[
{% raw %}
```sql
with source as (

    select * from {{ source('jaffle_shop', 'customers') }}

),

renamed as (

...
```
{% endraw %}
]

--

.right-column[
```sql
with source as (

    select * from raw.jaffle_shop.customers

),

renamed as (

...
```
]

???

**Demo:** Pause the deck here and jump into the IDE to show the following:
- Creating a .yml file and configuring sources (use text on Defining Sources slide)
- Changing the direct table references in the stg_customers model
- Show how the code compiles to the table reference based on the YML file
- Asking learners for how to update the stg_orders and stg_payments model

Then jump back to the slides to talk about source-freshness ðŸš€

---

# Sources are rendered as green nodes
They help users understand where data comes from (lineage)

<img src="/ui/img{{page.id}}/dag-source.png" class="img-center">

---

# Testing sources

?? 

Can you add tests to sources? Yes you can and you absolutely should! If there's something wrong with your data, you will be able to see if it was caused by something going wrong in your source data, or in one of your models.

.denser-text[

You can add tests to sources! And you should!
]

.denser-text[
```yml
version: 2

sources:
  - name: jaffle_shop
    database: raw
    schema: jaffle_shop
    tables:
      - name: customers
        identifier: customers
        columns:
          - name: id
            tests:
              - not_null
              - unique
```
]

.denser-text[

Being thoughtful about where you test helps you understand whether tests are failing because:
- The assumptions about your source data are no longer true
- Or your SQL has changed

This allows you to debug more quickly!

]


---

# Testing Sources

We can run tests on _only_ sources with the following command

`dbt test -s source:* `

This can be helpful in deployment - coming up soon

---


# Feeling fresh?


???

  - Now that we've defined our sources and we know how to test them ** jump back to intro slide ** 
  - Has that ever happened to you before? And if it has happened to you, do you have a reliable way of capturing that?

  - dbt has a command called source freshness that will allow you to check the freshness of your source tables. All you need to do is add a loaded_at field to your source definition, and under that add a freshness block.
  - The loaded_at field should be a column from the source data that reliably captures when that row was loaded into the warehouse. This usually something like an updated_at field. 
  - Your freshness blocks will then determine define the acceptable amount of time between the most recent record, and now, for a table to be considered "fresh". 
In this example, we have configured checks to run essentially every 12 hours. 

Optionally, specify a `loaded_at_field` and `freshness`:

.denser-text[

```yml
version: 2

sources:
  - name: jaffle_shop
    database: raw
    schema: jaffle_shop
    tables:
      - name: customers
        identifier: customers
      - name: orders
        identifier: orders
        loaded_at_field: _etl_loaded_at
        freshness:
          warn_after:
            count: 12
            period: hour
          error_after:
            count: 24
            period: hour

```

]

Then run `dbt source freshness`


---
## Snapshotting freshness

.denser-text[
```yml
$ dbt source freshness
Running with dbt=0.16.0
Found 5 models, 20 tests, 0 snapshots, 0 analyses, 130 macros, 0 operations, 0 seed files, 3 sources

17:29:17 | Concurrency: 4 threads (target='learn')
17:29:17 |
17:29:17 | 1 of 1 START freshness of jaffle_shop.orders......................... [RUN]
17:29:20 | 1 of 1 WARN freshness of jaffle_shop.orders.......................... [WARN in 2.91s]
17:29:21 | Done.
```
]

?? Running the command dbt source snapshot freshness will give you an output like this: 

### How does dbt check freshness?

--

.denser-text[
* dbt runs a SQL statement
{% raw %}
.left-column[
```sql
select
    max({{ loaded_at_field }}) as max_loaded_at,
    {{ current_timestamp() }} as snapshotted_at
from {{ source }}
```
{% endraw %}
]

.right-column[
```sql
select
    max(_batched_at) as max_loaded_at,
    convert_timezone('UTC', current_timestamp()) as snapshotted_at
from raw.stripe.payment
```
]
* Then it uses python to determine whether the delta is within the right range
]
---


.left-column-33[

???

Behind the scenes, dbt will calculate the difference between the max of the loaded_at field, so the most recent row uploaded, and the time at which the snapshot is being run. The results of this query are used to determine whether the source is fresh or not. 

## In dbt Cloud:

Adding this step to a job helps you understand if one of your data sources is out of date.

]

.right-column-66[
```bash
dbt source freshness
```
<img src="/ui/img{{page.id}}/freshness-viz.png" style="width: 100%;" class="img-center">
]

???

**Demo:** Use this an opportunity to demonstrate the source-freshness feature.  Do the following over in dbt Cloud:
- Copy the freshness configuration from `Feeling Fresh?` slide
- Run dbt source-freshness
- Show the code that is run against the warehouse to execute this
- Tweak the criteria to 1 hour warn and 2 hour error to show how that changes the results of the command

---

# In deployment

A common approach: Test the schema integrity of raw tables _before_
replacing production models.

```bash
dbt test -s source:*            # ensure no duplicates or unexpected nulls -- the job won't continue if these tests fail
dbt run                         # only runs if test above succeeds
dbt test --exclude source:*     # or you can even skip these!
dbt source freshness   # powers freshness viz in dbt Cloud
```

Another option: `source freshness` first, so that your job won't run on stale data.

???
More complex deployments:
- Blue/green that renames schema/database at last step (if all tests pass) or
leaves old objects in place (if a test fails)

---

class: subtitle

## Checkpoint
Given the following YML file, what will the following select statements compile to?

.left-column[
`sources.yml`
```yml
version: 2

sources:
  - name: event_data
    database: raw
    schema: snowplow
    tables:
      - name: events
        identifier: snowplow_events
```
]

{% raw %}
.right-column[
`SQL`

```sql
select *
from {{ source('event_data', 'events') }}
```
]
{% endraw %}

???

**Check for Understanding:** Ask the group to predict what the code on the right will compile to based on the YML file on the left.  Learners will have to pay close attention to the YML configuration

Slide 1: Compiles to `raw.snowplow.events`
Slide 2: Compiled to `raw.stripe.payments`

---

class: subtitle

## Checkpoint
Given the following YML file, what will the following select statements compile to?

.left-column[
`sources.yml`
```yml
version: 2

sources:
  - name: payment_data
    database: raw
    schema: stripe
    tables:
      - name: payments
        identifier: stripe_payments
```
]

{% raw %}
.right-column[
`SQL`

```sql
select *
from {{ source('payment_data','payments') }}
```
]
{% endraw %}

---

class: subtitle

## Checkpoint

- How does using sources, instead of directly referencing tables, impact our work as analytics engineers?
 
???

**Check for understanding:** Ask for 1-3 learners to share how they might use sources in their future workflow.

--

## Questions??

???

Pause for questions on sources based off what was covered.

---


class: subtitle

# Knowledge check

You should be able to:
* Define sources
* Select from a source in a model
* Add tests to a source
* Check the freshness of your source

{% include options/last_slide.html %}

---
## Further explorations

- (!!) I want to stage & query an external table that points to files in S3.

- (!!) Declare `external` properties ([read more](https://github.com/dbt-labs/dbt-external-tables))
