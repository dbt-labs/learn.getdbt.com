---
layout: presentation
title: Sources
estimated_teaching_time: 30
teaching_method: live demo + slides. Questions encouraged.
working_session: true
---

class: title, center, middle
# Sources

---

# If you've ever had this happen...

- I'm switching my email marketing platform. I want to know which final models depend on that source data.
--

- I'm switching the tool that extracts and loads _from_ my email
marketing platform. The table names used to have underscores, now they don't!
--

- I'm switching from Redshift to Snowflake. All of my source data will be
in a different database and schema.
--

- Nothing in this world is perfect. My data loading tools experience occasional
hiccups that result in delayed or duplicated data.
--

- (!!) I want to stage & query an external table that points to files in S3.

---

# Sources may be right for you!

- Easily declare and update the location of raw tables
    - `database` + `schema` for each source
    - `name`/`identifier` for each table
--
- Test data integrity of raw tables
    - Built-in: `unique`, `not_null`, `accepted_values`, `relationships`
    - Custom: whatever you want!
--
- Test the freshness of loaded data, based on thresholds you define
--

- (!!) Declare `external` properties ([read more](https://github.com/fishtown-analytics/dbt-external-tables))

---

# Defining sources
Sources are defined in `.yml` files in your `models/` directory.

(They can co-exist with `models:` blocks)

```yml
version: 2

sources:
  - name: stripe
    database: raw
    tables:
      - name: payment
```

---

# Selecting from sources

Use the {% raw %}`{{ source() }}`{% endraw %} function to select from a source in a model:

{% raw %}
```sql
with source as (

    select * from {{ source('stripe', 'payment') }}

),

renamed as (

...
```
{% endraw %}

---

# Sources are rendered as green nodes
They help users understand where data comes from (lineage)

<img src="/ui/img{{page.id}}/dag-source.png" class="img-center">

---

# Testing sources
You can add tests to sources! And you should!
.denser-text[
```yml
version: 2

sources:
  - name: stripe
    database: raw
    tables:
      - name: payment
        columns:
          - name: id
            tests:
              - not_null
              - unique
```
]
.dense-text[
Being thoughtful about where you test helps you understand whether tests are failing because:
- The assumptions about your source data are no longer true
- Or your SQL has changed

This allows you to debug more quickly!
]

---
# Feeling fresh?

Optionally, specify a `loaded_at_field` and `freshness`:
.denser-text[
```yml
version: 2

sources:
  - name: stripe
    database: raw
    loaded_at_field: _batched_at
    loader: airflow     # this is just for documentation

    freshness:
      warn_after: {count: 12, period: hour}
      error_after: {count: 24, period: hour}

    tables:
      - name: payment
```
Then run `dbt source snapshot-freshness`


]

---
# Snapshotting freshness

.denser-text[
```yml
$  dbt source snapshot-freshness
Running with dbt=0.16.0
Found 5 models, 20 tests, 0 snapshots, 0 analyses, 130 macros, 0 operations, 0 seed files, 3 sources

12:03:01 | Concurrency: 4 threads (target='learn')
12:03:01 |
12:03:01 | 1 of 1 START freshness of stripe.payment............................. [RUN]
12:03:04 | 1 of 2 PASS freshness of stripe.payment.............................. [PASS in 2.59s]
12:03:04 | Done.
```
]

### How does dbt check freshness?

--

.denser-text[
* dbt runs a SQL statement
{% raw %}
.left-column[
```sql
select
    max({{ loaded_at_field }}) as max_loaded_at,
    {{ current_timestamp() }} as snapshotted_at
from {{ source }}
```
{% endraw %}
]

.right-column[
```sql
select
    max(_batched_at) as max_loaded_at,
    convert_timezone('UTC', current_timestamp()) as snapshotted_at
from raw.stripe.payment
```
]
* Then it uses python to determine whether the delta between the two timestamps is within the right range
]
---


.left-column-33[
## In dbt Cloud:

Adding this step to a job helps you understand if one of your data sources is out of date.

]

.right-column-66[
```bash
dbt source snapshot-freshness
```
<img src="/ui/img{{page.id}}/freshness-viz.png" style="width: 100%;" class="img-center">
]

---

# In deployment

A common approach: Test the schema integrity of raw tables _before_
replacing production models.

```bash
dbt test -m source:*            # ensure no duplicates or unexpected nulls -- the job won't continue if these tests fail
dbt run                         # only runs if test above succeeds
dbt test --exclude source:*     # or you can even skip these!
dbt source snapshot-freshness   # powers freshness viz in dbt Cloud
```

Another option: `snapshot-freshness` first, so that your job won't run on stale data.

???
More complex deployments:
- Blue/green that renames schema/database at last step (if all tests pass) or
leaves old objects in place (if a test fails)

---

class: subtitle

# Knowledge check

You should be able to:
* Define sources
* Select from a source in a model
* Add tests to a source
* Check the freshness of your source

{% include options/next_presentation.html %}
